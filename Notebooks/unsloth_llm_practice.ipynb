{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dea41716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import datetime as dt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "412b779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Retrieve the token\n",
    "token = os.environ[\"openai_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c16cddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=token)  # will now pick up OPENAI_API_KEY from env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039d85ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['babbage-002', 'dall-e-2', 'dall-e-3', 'davinci-002', 'gpt-3.5-turbo', 'gpt-3.5-turbo-0125', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-instruct', 'gpt-3.5-turbo-instruct-0914', 'gpt-4.1', 'gpt-4.1-2025-04-14', 'gpt-4.1-mini', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-nano', 'gpt-4.1-nano-2025-04-14', 'gpt-4o', 'gpt-4o-2024-05-13', 'gpt-4o-2024-08-06', 'gpt-4o-2024-11-20', 'gpt-4o-audio-preview', 'gpt-4o-audio-preview-2024-10-01', 'gpt-4o-audio-preview-2024-12-17', 'gpt-4o-audio-preview-2025-06-03', 'gpt-4o-mini', 'gpt-4o-mini-2024-07-18', 'gpt-4o-mini-audio-preview', 'gpt-4o-mini-audio-preview-2024-12-17', 'gpt-4o-mini-search-preview', 'gpt-4o-mini-search-preview-2025-03-11', 'gpt-4o-mini-transcribe', 'gpt-4o-mini-tts', 'gpt-4o-search-preview', 'gpt-4o-search-preview-2025-03-11', 'gpt-4o-transcribe', 'gpt-5', 'gpt-5-2025-08-07', 'gpt-5-chat-latest', 'gpt-5-mini', 'gpt-5-mini-2025-08-07', 'gpt-5-nano', 'gpt-5-nano-2025-08-07', 'gpt-audio', 'gpt-audio-2025-08-28', 'gpt-image-1', 'o1', 'o1-2024-12-17', 'o1-mini', 'o1-mini-2024-09-12', 'o3']\n"
     ]
    }
   ],
   "source": [
    "available = [m.id for m in client.models.list().data]\n",
    "print(sorted(available)[:50])  # sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a905a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PARSE = \"gpt-4o-mini\"  # Stage 1\n",
    "MODEL_PLAN  = \"o3\"           # Stage 2\n",
    "\n",
    "# for your existing generate_events():\n",
    "MODEL = MODEL_PARSE\n",
    "TEMPERATURE = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPERATURE = 0.3\n",
    "MAX_TOKENS = 500\n",
    "topic = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46e0da53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt engineering\n",
    "# prompt system message\n",
    "SYSTEM_PROMPT = \"\"\"You are a calendar event parser that outputs ONLY a JSON object with one key: \"events\". Never include prose, comments, or markdown.\"\"\"\n",
    "# main prompt \n",
    "USER_TEMPLATE = \"\"\"\n",
    "Return ONLY a JSON object with a single key \"events\": an array of event objects. If none, return {\"events\": []}.\n",
    "\n",
    "EVENT SCHEMA (each object)\n",
    "{\n",
    "  \"title\": \"string\",\n",
    "  \"event_date\": \"YYYY-MM-DD\",\n",
    "  \"event_time\": \"HH:MM\" | \"\",\n",
    "  \"end_time\": \"HH:MM\" | \"\",\n",
    "  \"end_date\": \"YYYY-MM-DD\",\n",
    "  \"timezone\": \"\",                     // leave \"\" unless explicitly given\n",
    "  \"location\": \"string\",\n",
    "  \"invitees\": [\"email\", ...],\n",
    "  \"notifications\": [{\"method\":\"email|popup\",\"minutes\":int}],\n",
    "  \"recurrence\": \"RRULE string or ''\",\n",
    "  \"confidence\": 0.0-1.0\n",
    "}\n",
    "\n",
    "RULES\n",
    "- Times: 24-hour; \"noon\"→\"12:00\"; \"midnight\"→\"00:00\".\n",
    "- Anchor relative dates to TODAY={TODAY_ISO}.\n",
    "- Do NOT invent timezones; use \"\" unless explicitly given.\n",
    "- For time ranges (\"7-9pm\"), set event_time to start (\"19:00\") and leave end_time \"\".\n",
    "- RRULE examples:\n",
    "  - Weekly Monday: \"RRULE:FREQ=WEEKLY;BYDAY=MO\"\n",
    "  - Weekdays: \"RRULE:FREQ=WEEKLY;BYDAY=MO,TU,WE,TH,FR\"\n",
    "  - Daily x10: \"RRULE:FREQ=DAILY;COUNT=10\"\n",
    "  - 1st Friday monthly: \"RRULE:FREQ=MONTHLY;BYDAY=1FR\"\n",
    "  - None: \"\"\n",
    "\n",
    "CONFIDENCE\n",
    "Scale 0-1: high when explicit/consistent; medium when minor inference; low when ambiguous.\n",
    "\n",
    "OUTPUT SHAPE (strict)\n",
    "{\"events\":[ /* zero or more event objects per schema */ ]}\n",
    " \n",
    "INPUT\n",
    "{USER_TEXT}\n",
    "\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88b1fbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_prompt(user_text: str, today_iso: str) -> str:\n",
    "    return USER_TEMPLATE.replace(\"{TODAY_ISO}\", today_iso).replace(\"{USER_TEXT}\", user_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de383f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_json_parse(raw: str):\n",
    "    s = raw.strip()\n",
    "    if s.startswith(\"```\"):\n",
    "        # strip code fences defensively (rare with JSON mode, but cheap)\n",
    "        s = s.strip(\"`\")\n",
    "        s = s[s.find(\"\\n\")+1:]\n",
    "        if s.endswith(\"```\"):\n",
    "            s = s[:s.rfind(\"```\")]\n",
    "    try:\n",
    "        obj = json.loads(s)\n",
    "        # Expect {\"events\": [...]}\n",
    "        if isinstance(obj, dict) and \"events\" in obj and isinstance(obj[\"events\"], list):\n",
    "            return obj[\"events\"]\n",
    "        # Fallback: if provider returns a top-level list, accept it\n",
    "        if isinstance(obj, list):\n",
    "            return obj\n",
    "        return []\n",
    "    except Exception:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d38c07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_MOCK = True  # flip to False when you have credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6dc722ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mock_generate_events(user_text: str, today_iso: str):\n",
    "    # Minimal, deterministic mock for smoke tests\n",
    "    if \"Dinner with John\" in user_text:\n",
    "        return [{\n",
    "            \"title\": \"Dinner with John\",\n",
    "            \"event_date\": today_iso,\n",
    "            \"event_time\": \"19:00\",\n",
    "            \"end_time\": \"\",\n",
    "            \"end_date\": today_iso,\n",
    "            \"timezone\": \"\",\n",
    "            \"location\": \"Boston Pizza\",\n",
    "            \"invitees\": [\"alex@example.com\"],\n",
    "            \"notifications\": [{\"method\": \"popup\", \"minutes\": 10}],\n",
    "            \"recurrence\": \"\",\n",
    "            \"confidence\": 0.85\n",
    "        }]\n",
    "    return []\n",
    "\n",
    "def generate_events(user_text: str, today: dt.date | None = None):\n",
    "    today = today or dt.date.today()\n",
    "\n",
    "    if USE_MOCK:\n",
    "        events = mock_generate_events(user_text, today.isoformat())\n",
    "        raw = json.dumps({\"events\": events})\n",
    "        diag = {\"engine\":\"mock\",\"model\":\"mock\",\"latency_ms\":1,\"input_tokens\":0,\"output_tokens\":0}\n",
    "        return events, diag, raw\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": build_user_prompt(user_text, today.isoformat())},\n",
    "    ]\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            response_format={\"type\": \"json_object\"},  # force valid JSON\n",
    "            messages=messages,\n",
    "        )\n",
    "        raw = resp.choices[0].message.content\n",
    "        events = safe_json_parse(raw)\n",
    "        diag = {\n",
    "            \"engine\": \"byok\",\n",
    "            \"model\": resp.model,\n",
    "            \"latency_ms\": int((time.time() - t0) * 1000),\n",
    "            \"input_tokens\": getattr(resp, \"usage\", None).prompt_tokens if getattr(resp, \"usage\", None) else None,\n",
    "            \"output_tokens\": getattr(resp, \"usage\", None).completion_tokens if getattr(resp, \"usage\", None) else None,\n",
    "        }\n",
    "        return events, diag, raw\n",
    "    except OpenAIError as e:\n",
    "        # Fallback so your app keeps working during quota/rate issues\n",
    "        events = mock_generate_events(user_text, today.isoformat())\n",
    "        raw = json.dumps({\"events\": events})\n",
    "        diag = {\n",
    "            \"engine\": \"fallback-mock\",\n",
    "            \"model\": \"mock\",\n",
    "            \"latency_ms\": int((time.time() - t0) * 1000),\n",
    "            \"error\": str(e)[:200],\n",
    "        }\n",
    "        return events, diag, raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7333c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diag: {'engine': 'mock', 'model': 'mock', 'latency_ms': 1, 'input_tokens': 0, 'output_tokens': 0}\n",
      "[\n",
      "  {\n",
      "    \"title\": \"Dinner with John\",\n",
      "    \"event_date\": \"2025-09-19\",\n",
      "    \"event_time\": \"19:00\",\n",
      "    \"end_time\": \"\",\n",
      "    \"end_date\": \"2025-09-19\",\n",
      "    \"timezone\": \"\",\n",
      "    \"location\": \"Boston Pizza\",\n",
      "    \"invitees\": [\n",
      "      \"alex@example.com\"\n",
      "    ],\n",
      "    \"notifications\": [\n",
      "      {\n",
      "        \"method\": \"popup\",\n",
      "        \"minutes\": 10\n",
      "      }\n",
      "    ],\n",
      "    \"recurrence\": \"\",\n",
      "    \"confidence\": 0.85\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# 3) Quick smoke test\n",
    "sample = \"Dinner with John tomorrow 7pm at Boston Pizza; alex@example.com; remind me 10 minutes before.\"\n",
    "events, diag, raw = generate_events(sample)\n",
    "print(\"diag:\", diag)\n",
    "print(json.dumps(events, indent=2)[:1200])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandboxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
